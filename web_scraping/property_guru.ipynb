{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db6d4b16-9d5a-4e24-95d5-125bd345f0bb",
   "metadata": {},
   "source": [
    "This notebook is used to scrape data for ready to buy projects from __[PropertyGuru.com.my](https://www.propertyguru.com.my/new-property-launch)__ website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315062d5-1492-44df-8882-26afa0306b48",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Import required packages\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddae499b-ed50-4a7e-b8f4-7fea1e37ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "# import undetected_chromedriver as the site has anti bot countermeasure\n",
    "import undetected_chromedriver as uc \n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec487d4-6bc5-4a72-bdcc-9bd5143a3bc4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">General helper functions</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773675e0-328a-45d5-afec-fc29daf6799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tag(text):\n",
    "    return BeautifulSoup(text, \"lxml\").text\n",
    "\n",
    "def click_by_xpath(driver, xpath):\n",
    "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, xpath))).click()\n",
    "\n",
    "def get_by_xpath(driver, xpath):\n",
    "    try:\n",
    "        return WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, xpath)))\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def hover_and_click_by_xpath(driver, xpath):\n",
    "    element = get_by_xpath(driver, xpath)\n",
    "    action = ActionChains(driver)\n",
    "    action.move_to_element(element).perform()\n",
    "    time.sleep(1)\n",
    "    click_by_xpath(driver, xpath)\n",
    "    \n",
    "def get_element_text(elements, tag, attrs):\n",
    "    try:    \n",
    "        element = elements.find(tag, attrs=attrs);\n",
    "        if element:\n",
    "            return element.text.strip()\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_price(text):\n",
    "    if text is None:\n",
    "        return None\n",
    "    return float(re.sub(r'[^0-9.]', '', text))\n",
    "\n",
    "def get_square_feet(text):\n",
    "    match = re.search(r'(\\d+) sqft', text)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def get_year(text):\n",
    "    match = re.search(r'(\\d{4})$', text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return 'N/A'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc3a542-5cc5-4e5f-8342-79f365f51e96",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Page content related helper functions\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c35788-8e90-4d66-a623-5676dde17774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accept_cookies_policy(driver):\n",
    "    try:\n",
    "        # accept cookies policy\n",
    "        click_by_xpath(driver, \"//button[contains(text(),'Accept')]\")\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        # catch exception and do nothing\n",
    "        pass\n",
    "    \n",
    "def load_all_projects(driver):\n",
    "    try:\n",
    "        while True:\n",
    "            # find load more button for ready to buy projects\n",
    "            soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "            project_title = soup.find(\"h3\", string='Ready to Buy Projects')\n",
    "            project_div = project_title.parent\n",
    "            load_more_button = project_div.find('button', attrs={'class': 'load-more-button'})\n",
    "            if load_more_button is None:\n",
    "                # end the load if load more button does not exists\n",
    "                return            \n",
    "            # get load more index\n",
    "            match = re.search('(\\d+)', load_more_button.text)\n",
    "            if match is None:\n",
    "                # end the loop if load more button contains no integer value\n",
    "                return\n",
    "            load_more_index = int(match.group(0))     \n",
    "            print(f'Load more: {load_more_index}')\n",
    "            # get load more button element and scroll into view so selenium can click on it\n",
    "            load_more_xpath = f\"//button[normalize-space()='Load More ({load_more_index})']\"\n",
    "            load_more_element = get_by_xpath(driver, load_more_xpath)\n",
    "            driver.execute_script('arguments[0].scrollIntoView(false)', load_more_element)\n",
    "            time.sleep(3)\n",
    "            # click load more button\n",
    "            click_by_xpath(driver, load_more_xpath)\n",
    "            time.sleep(3)\n",
    "    except Exception as e:\n",
    "        if hasattr(e, 'message'):\n",
    "            print(f'load_all_projects: {e.message}')\n",
    "        else:\n",
    "            print(f'load_all_projects: {e}')\n",
    "\n",
    "def get_projects(driver, project_list):\n",
    "    # find all ready to buy projects\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    project_title = soup.find(\"h3\", string='Ready to Buy Projects')\n",
    "    project_div = project_title.parent\n",
    "    projects = project_div.find_all(\"div\", attrs={\"class\": \"project-listing-card-root\"})\n",
    "    print(f'Total projects: {len(projects)}')\n",
    "    for project in projects:\n",
    "        project_list.extend(get_project_info(project))\n",
    "\n",
    "def get_project_info(project):\n",
    "    title = get_element_text(project, \"h4\", attrs={\"class\":\"project-listing-card__title\"})\n",
    "    address = get_element_text(project, \"span\", attrs={\"class\":\"project-listing-card__address\"})\n",
    "    launched_in = get_element_text(project, \"div\", attrs={\"class\":\"project-listing-card__status\"})\n",
    "    labels = project.find_all(\"div\", attrs={\"class\":\"project-listing-card__labels--pill\"})\n",
    "    tenure = labels[0].text.strip()\n",
    "    type = labels[1].text.strip()\n",
    "    link_element = project.find(\"a\", attrs={\"class\":\"actionable-link\"})\n",
    "    project_link = link_element[\"href\"]\n",
    "    image_link = link_element.find(\"img\")['src']\n",
    "    project_basic_info = {\n",
    "        'title': title,\n",
    "        'type': type,\n",
    "        'tenure': tenure,\n",
    "        'launched_in': launched_in,\n",
    "        'address': address,        \n",
    "        'project_link': project_link,\n",
    "        'image_link': image_link\n",
    "    }    \n",
    "    return get_project_detail(driver, project_basic_info)\n",
    "    \n",
    "def get_project_detail(driver, project_info):\n",
    "    print(f\"Getting project detail for: {project_info['title']}\")\n",
    "    project_list = []\n",
    "    # go to project link\n",
    "    driver.get(project_info['project_link'])\n",
    "    show_more_xpath = \"//button[normalize-space()='Show more']\"\n",
    "    show_more_button = get_by_xpath(driver, show_more_xpath)\n",
    "    # check if show more button exists. If exists,\n",
    "    # click on it to load the complete project description\n",
    "    if show_more_button:\n",
    "        driver.execute_script('arguments[0].scrollIntoView(false)', show_more_button)\n",
    "        time.sleep(1)\n",
    "        # show more button blocked by sticky div\n",
    "        # hover over to the element and click\n",
    "        hover_and_click_by_xpath(driver, show_more_xpath)\n",
    "    # load page source to BeatifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    # get project detail section\n",
    "    project_div = soup.find(\"div\", attrs={\"class\":\"col-lg-8 col-md-12\"})\n",
    "    description = get_element_text(project_div, \"div\", attrs={\"class\":\"description\"})\n",
    "    developer_div = project_div.find(\"div\", string='Developer')\n",
    "    developer = developer_div.next_sibling.text.strip()\n",
    "    bedrooms_types_nav = project_div.find(\"nav\", attrs={'data-automation-id':'unit-types-navbar'})\n",
    "    project_info['description'] = description\n",
    "    project_info['developer'] = developer\n",
    "    if bedrooms_types_nav:\n",
    "        bedrooms_types = bedrooms_types_nav.find_all(\"a\")\n",
    "        for bedrooms_type in bedrooms_types:\n",
    "            bedrooms_type_xpath = f\"//a[normalize-space()='{bedrooms_type.text.strip()}']\"\n",
    "            bedrooms_type_tab = get_by_xpath(driver, bedrooms_type_xpath)\n",
    "            driver.execute_script('arguments[0].scrollIntoView(false)', bedrooms_type_tab)\n",
    "            time.sleep(1)\n",
    "            hover_and_click_by_xpath(driver, bedrooms_type_xpath)\n",
    "            time.sleep(2)\n",
    "            # reload page source\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            project_div = soup.find(\"div\", attrs={\"class\":\"col-lg-8 col-md-12\"})\n",
    "            price = get_element_text(project_div, \"span\", attrs={\"class\":\"price__label\"})\n",
    "            if price is None:\n",
    "                # skip is price span does not exists\n",
    "                continue\n",
    "            project_list.extend(get_unit_type_info(driver, project_info, project_div))\n",
    "    else:\n",
    "        project_list.extend(get_unit_type_info(driver, project_info, project_div))\n",
    "    return project_list\n",
    "\n",
    "def get_unit_type_info(driver, project_info, project_div):\n",
    "    project_list = []\n",
    "    unit_types_div = project_div.find(\"div\", attrs={'class':'property-unit-type-selection-root'})\n",
    "    unit_types = unit_types_div.find_all(\"div\", attrs={'class':'box'})\n",
    "    tab_idx = 0\n",
    "    for unit_type in unit_types:\n",
    "        if tab_idx > 0:\n",
    "            # click on tab to load unit type summary for second tab onwards\n",
    "            unit_type_label = get_element_text(unit_type, \"div\", attrs={\"class\":\"box__label\"})        \n",
    "            unit_type_xpath = f\"//div[normalize-space()='{unit_type_label}']\"\n",
    "            try:\n",
    "                # try click unit type tab with full label value\n",
    "                unit_type_tab = get_by_xpath(driver, unit_type_xpath)\n",
    "                time.sleep(1)\n",
    "                hover_and_click_by_xpath(driver, unit_type_xpath)\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                # try click unit type tab with partial label value\n",
    "                unit_type_xpath = f\"//div[@class='box__label'][contains(text(),'{unit_type_label}')]\"\n",
    "                unit_type_tab = get_by_xpath(driver, unit_type_xpath)\n",
    "                time.sleep(1)\n",
    "                hover_and_click_by_xpath(driver, unit_type_xpath)\n",
    "                time.sleep(2)\n",
    "        tab_idx += 1\n",
    "        # reload page source\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        project_div = soup.find(\"div\", attrs={\"class\":\"col-lg-8 col-md-12\"})\n",
    "        price = get_element_text(project_div, \"span\", attrs={\"class\":\"price__label\"})\n",
    "        if price is None:\n",
    "            # skip is price span does not exists\n",
    "            continue\n",
    "        summary_div = project_div.find(\"div\", attrs={\"class\":\"summary\"})\n",
    "        summary_span = summary_div.find_all(\"span\") \n",
    "        bedroom = summary_span[0].text.strip()\n",
    "        bathroom = summary_span[1].text.strip()\n",
    "        square_feet = get_square_feet(summary_span[2].text.strip())\n",
    "        price_per_square_foot = get_price(summary_span[3].text.strip())\n",
    "        # calculate price from square feet and price per square foot\n",
    "        # as price in span in some projects not showing the correct value\n",
    "        price = square_feet * price_per_square_foot\n",
    "        furnishing = get_element_text(project_div, \"span\", attrs={\"class\":\"furnishing__value\"})\n",
    "        project_list.append({\n",
    "            'title': project_info['title'],\n",
    "            'type': project_info['type'],\n",
    "            'tenure': project_info['tenure'],\n",
    "            'price': f'{price:.2f}',\n",
    "            'square_feet': square_feet,\n",
    "            'price_per_square_foot': price_per_square_foot,\n",
    "            'bedroom': bedroom,\n",
    "            'bathroom': bathroom,\n",
    "            'furnishing': furnishing,\n",
    "            'launched_in': get_year(project_info['launched_in']),\n",
    "            'address': project_info['address'],\n",
    "            'developer': project_info['developer'],\n",
    "            'description': project_info['description'],\n",
    "            'project_link': project_info['project_link'],\n",
    "            'image_link': project_info['image_link'],\n",
    "        })\n",
    "    return project_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de3d6d5-7471-4a66-b052-1518f097e8e6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Scrape ready to buy projects data from property guru web site\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28809392-f357-491f-9e37-a5026773bb65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load more: 87\n",
      "Load more: 79\n",
      "Load more: 71\n",
      "Load more: 63\n",
      "Load more: 55\n",
      "Load more: 47\n",
      "Load more: 39\n",
      "Load more: 31\n",
      "Load more: 23\n",
      "Load more: 15\n",
      "Load more: 7\n",
      "Total projects: 53\n",
      "Getting project detail for: Pinnacle SJ\n",
      "Getting project detail for: Ponderosa Vista 2-Storey Semi-Detached\n",
      "Getting project detail for: Ferrous 2\n",
      "Getting project detail for: BON KIARA\n",
      "Getting project detail for: Blooming Residence\n",
      "Getting project detail for: Candella\n",
      "Getting project detail for: SouthPlace 2 Residences\n",
      "Getting project detail for: Miranda Hill\n",
      "Getting project detail for: Sejati Lakeside 2\n",
      "Getting project detail for: Tiara Sendayan\n",
      "Getting project detail for: Aderyn\n",
      "Getting project detail for: The Senai Garden\n",
      "Getting project detail for: Residensi Dian II\n",
      "Getting project detail for: Hana Residences\n",
      "Getting project detail for: Interpoint\n",
      "Getting project detail for: Sunway Flora Residences\n",
      "Getting project detail for: Pearl Garden - Panorama Lapangan Mutiara\n",
      "Getting project detail for: Senadi Hills\n",
      "Getting project detail for: Alora Residences @ 2fifth Avenue Subang Jaya\n",
      "Getting project detail for: ALTON SKYVILLAS\n",
      "Getting project detail for: Chorus\n",
      "Getting project detail for: Hanami Residences\n",
      "Getting project detail for: Ruby Hills @ BBKP\n",
      "Getting project detail for: Eco Horizon @ Beldon Collection\n",
      "Getting project detail for: Eco Horizon @ Beldon Collection\n",
      "Getting project detail for: Prestige Residence\n",
      "Getting project detail for: Greenwoods Seraya\n",
      "Getting project detail for: Myra Cove\n",
      "Getting project detail for: SkyLake Residence\n",
      "Getting project detail for: Emerald Garden 3\n",
      "Getting project detail for: Sebayu Bungalow Plots\n",
      "Getting project detail for: Ritma Perdana (Townhouse), LBS Alam Perdana\n",
      "Getting project detail for: KITA Mesra (Townhouse)\n",
      "Getting project detail for: Pangsapuri Kita Sejati\n",
      "Getting project detail for: Ponderosa Vista 2-Storey Terrace\n",
      "Getting project detail for: Sky Trees Commercial\n",
      "Getting project detail for: Edelweiss Sofo & Serviced Residences\n",
      "Getting project detail for: Ferringhi Residence 2\n",
      "Getting project detail for: Danga Sutera\n",
      "Getting project detail for: Southern Marina Residences\n",
      "Getting project detail for: Jauhar @ Bayu Damai\n",
      "Getting project detail for: Rivercity Business Park @ Batu Pahat\n",
      "Getting project detail for: Suasana Iskandar Johor Bahru\n",
      "Getting project detail for: Setia Ecohill Walk\n",
      "Getting project detail for: Indah Heights\n",
      "Getting project detail for: D'Suites, Horizon Hills\n",
      "Getting project detail for: ViiA Residences at KL Eco City\n",
      "Getting project detail for: The Effingham\n",
      "Getting project detail for: Setia V Residences\n",
      "Getting project detail for: Setia Sky 88\n",
      "Getting project detail for: Molek Pine 4\n",
      "Getting project detail for: 9 Bukit Utama\n",
      "Getting project detail for: 9 Bukit Utama\n"
     ]
    }
   ],
   "source": [
    "url='https://www.propertyguru.com.my/new-property-launch'\n",
    "driver = uc.Chrome()\n",
    "driver.maximize_window() \n",
    "driver.get(url)\n",
    "\n",
    "# wait for cookies policy window\n",
    "time.sleep(3)\n",
    "accept_cookies_policy(driver)\n",
    "time.sleep(1)\n",
    "load_all_projects(driver)\n",
    "project_list = []\n",
    "get_projects(driver, project_list)\n",
    "\n",
    "data_folder = '../data'\n",
    "# create data folder if it does not exists\n",
    "if not os.path.exists(data_folder): \n",
    "    os.makedirs(data_folder)\n",
    "\n",
    "# save scraped data into a csv file\n",
    "today_date = datetime.now()\n",
    "data_folder = '../data'\n",
    "filename = f'property_guru_ready_to_buy_projects_{today_date.strftime(\"%Y-%m-%d\")}.csv'\n",
    "df = pd.DataFrame(project_list)\n",
    "df.to_csv(f'{data_folder}/{filename}', sep=',', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
