{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cbc11ea-b1ed-4209-9141-78ff1165b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "# import undetected_chromedriver as the site has anti bot countermeasure\n",
    "import undetected_chromedriver as uc \n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "773675e0-328a-45d5-afec-fc29daf6799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def remove_html_tag(text):\n",
    "    return BeautifulSoup(text, \"lxml\").text\n",
    "\n",
    "def click_by_xpath(driver, xpath):\n",
    "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, xpath))).click()\n",
    "\n",
    "def get_by_xpath(driver, xpath):\n",
    "    try:\n",
    "        return WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, xpath)))\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def hover_and_click_by_xpath(driver, xpath):\n",
    "    element = get_by_xpath(driver, xpath)\n",
    "    action = ActionChains(driver)\n",
    "    action.move_to_element(element).perform()\n",
    "    time.sleep(1)\n",
    "    click_by_xpath(driver, xpath)\n",
    "    \n",
    "def get_element_text(elements, tag, attrs):\n",
    "    try:    \n",
    "        element = elements.find(tag, attrs=attrs);\n",
    "        if element:\n",
    "            return element.text.strip()\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_price(text):\n",
    "    if text is None:\n",
    "        return None\n",
    "    return float(re.sub(r'[^0-9.]', '', text))\n",
    "\n",
    "def get_square_feet(text):\n",
    "    match = re.search(r'(\\d+) sqft', text)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def get_year(text):\n",
    "    match = re.search(r'(\\d{4})$', text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return 'N/A'\n",
    "    \n",
    "def accept_cookies_policy(driver):\n",
    "    try:\n",
    "        # accept cookies policy\n",
    "        click_by_xpath(driver, \"//button[normalize-space()='Accept Cookies']\")\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        # catch exception and do nothing\n",
    "        pass\n",
    "    \n",
    "def load_all_projects(driver):\n",
    "    try:\n",
    "        while True:\n",
    "            # find load more button for ready to buy projects\n",
    "            soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "            project_title = soup.find(\"h3\", string='Ready to Buy Projects')\n",
    "            project_div = project_title.parent\n",
    "            load_more_button = project_div.find('button', attrs={'class': 'load-more-button'})\n",
    "            if load_more_button is None:\n",
    "                # end the load if load more button does not exists\n",
    "                return            \n",
    "            # get load more index\n",
    "            match = re.search('(\\d+)', load_more_button.text)\n",
    "            if match is None:\n",
    "                # end the loop if load more button contains no integer value\n",
    "                return\n",
    "            load_more_index = int(match.group(0))     \n",
    "            print(f'Load more: {load_more_index}')\n",
    "            # get load more button element and scroll into view so selenium can click on it\n",
    "            load_more_xpath = f\"//button[normalize-space()='Load More ({load_more_index})']\"\n",
    "            load_more_element = get_by_xpath(driver, load_more_xpath)\n",
    "            driver.execute_script('arguments[0].scrollIntoView(false)', load_more_element)\n",
    "            time.sleep(3)\n",
    "            # click load more button\n",
    "            click_by_xpath(driver, load_more_xpath)\n",
    "            time.sleep(3)\n",
    "    except Exception as e:\n",
    "        if hasattr(e, 'message'):\n",
    "            print(f'load_all_projects: {e.message}')\n",
    "        else:\n",
    "            print(f'load_all_projects: {e}')\n",
    "\n",
    "def get_projects(driver, project_list):\n",
    "    # find all ready to buy projects\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    project_title = soup.find(\"h3\", string='Ready to Buy Projects')\n",
    "    project_div = project_title.parent\n",
    "    projects = project_div.find_all(\"div\", attrs={\"class\": \"project-listing-card-root\"})\n",
    "    print(f'Total projects: {len(projects)}')\n",
    "    for project in projects:\n",
    "        project_list.extend(get_project_info(project))\n",
    "\n",
    "def get_project_info(project):\n",
    "    title = get_element_text(project, \"h4\", attrs={\"class\":\"project-listing-card__title\"})\n",
    "    address = get_element_text(project, \"span\", attrs={\"class\":\"project-listing-card__address\"})\n",
    "    launched_in = get_element_text(project, \"div\", attrs={\"class\":\"project-listing-card__status\"})\n",
    "    labels = project.find_all(\"div\", attrs={\"class\":\"project-listing-card__labels--pill\"})\n",
    "    tenure = labels[0].text.strip()\n",
    "    type = labels[1].text.strip()\n",
    "    link_element = project.find(\"a\", attrs={\"class\":\"actionable-link\"})\n",
    "    project_link = link_element[\"href\"]\n",
    "    image_link = link_element.find(\"img\")['src']\n",
    "    project_basic_info = {\n",
    "        'title': title,\n",
    "        'type': type,\n",
    "        'tenure': tenure,\n",
    "        'launched_in': launched_in,\n",
    "        'address': address,        \n",
    "        'project_link': project_link,\n",
    "        'image_link': image_link\n",
    "    }    \n",
    "    return get_project_detail(driver, project_basic_info)\n",
    "    \n",
    "def get_project_detail(driver, project_info):\n",
    "    print(f\"Getting project detail for: {project_info['title']}\")\n",
    "    project_list = []\n",
    "    # go to project link\n",
    "    driver.get(project_info['project_link'])\n",
    "    show_more_xpath = \"//button[normalize-space()='Show more']\"\n",
    "    show_more_button = get_by_xpath(driver, show_more_xpath)\n",
    "    # check if show more button exists. If exists,\n",
    "    # click on it to load the complete project description\n",
    "    if show_more_button:\n",
    "        driver.execute_script('arguments[0].scrollIntoView(false)', show_more_button)\n",
    "        time.sleep(1)\n",
    "        # show more button blocked by sticky div\n",
    "        # hover over to the element and click\n",
    "        hover_and_click_by_xpath(driver, show_more_xpath)\n",
    "    # load page source to BeatifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    # get project detail section\n",
    "    project_div = soup.find(\"div\", attrs={\"class\":\"col-lg-8 col-md-12\"})\n",
    "    description = get_element_text(project_div, \"div\", attrs={\"class\":\"description\"})\n",
    "    developer_div = project_div.find(\"div\", string='Developer')\n",
    "    developer = developer_div.next_sibling.text.strip()\n",
    "    bedrooms_types_nav = project_div.find(\"nav\", attrs={'data-automation-id':'unit-types-navbar'})\n",
    "    project_info['description'] = description\n",
    "    project_info['developer'] = developer\n",
    "    if bedrooms_types_nav:\n",
    "        bedrooms_types = bedrooms_types_nav.find_all(\"a\")\n",
    "        for bedrooms_type in bedrooms_types:\n",
    "            bedrooms_type_xpath = f\"//a[normalize-space()='{bedrooms_type.text.strip()}']\"\n",
    "            bedrooms_type_tab = get_by_xpath(driver, bedrooms_type_xpath)\n",
    "            driver.execute_script('arguments[0].scrollIntoView(false)', bedrooms_type_tab)\n",
    "            time.sleep(1)\n",
    "            hover_and_click_by_xpath(driver, bedrooms_type_xpath)\n",
    "            time.sleep(2)\n",
    "            # reload page source\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            project_div = soup.find(\"div\", attrs={\"class\":\"col-lg-8 col-md-12\"})\n",
    "            price = get_element_text(project_div, \"span\", attrs={\"class\":\"price__label\"})\n",
    "            if price is None:\n",
    "                # skip is price span does not exists\n",
    "                continue\n",
    "            project_list.extend(get_unit_type_info(driver, project_info, project_div))\n",
    "    else:\n",
    "        project_list.extend(get_unit_type_info(driver, project_info, project_div))\n",
    "    return project_list\n",
    "\n",
    "def get_unit_type_info(driver, project_info, project_div):\n",
    "    project_list = []\n",
    "    unit_types_div = project_div.find(\"div\", attrs={'class':'property-unit-type-selection-root'})\n",
    "    unit_types = unit_types_div.find_all(\"div\", attrs={'class':'box'})\n",
    "    tab_idx = 0\n",
    "    for unit_type in unit_types:\n",
    "        if tab_idx > 0:\n",
    "            # click on tab to load unit type summary for second tab onwards\n",
    "            unit_type_label = get_element_text(unit_type, \"div\", attrs={\"class\":\"box__label\"})        \n",
    "            unit_type_xpath = f\"//div[normalize-space()='{unit_type_label}']\"\n",
    "            try:\n",
    "                # try with click unit type tab with full label value\n",
    "                unit_type_tab = get_by_xpath(driver, unit_type_xpath)\n",
    "                time.sleep(1)\n",
    "                hover_and_click_by_xpath(driver, unit_type_xpath)\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                # try with click unit type tab with partial label value\n",
    "                unit_type_xpath = f\"//div[@class='box__label'][contains(text(),'{unit_type_label}')]\"\n",
    "                unit_type_tab = get_by_xpath(driver, unit_type_xpath)\n",
    "                time.sleep(1)\n",
    "                hover_and_click_by_xpath(driver, unit_type_xpath)\n",
    "                time.sleep(2)\n",
    "        tab_idx += 1\n",
    "        # reload page source\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        project_div = soup.find(\"div\", attrs={\"class\":\"col-lg-8 col-md-12\"})\n",
    "        price = get_element_text(project_div, \"span\", attrs={\"class\":\"price__label\"})\n",
    "        if price is None:\n",
    "            # skip is price span does not exists\n",
    "            continue\n",
    "        summary_div = project_div.find(\"div\", attrs={\"class\":\"summary\"})\n",
    "        summary_span = summary_div.find_all(\"span\") \n",
    "        bedroom = summary_span[0].text.strip()\n",
    "        bathroom = summary_span[1].text.strip()\n",
    "        square_feet = get_square_feet(summary_span[2].text.strip())\n",
    "        price_per_square_feet = get_price(summary_span[3].text.strip())\n",
    "        # calculate price from square feet and price per square feet\n",
    "        # as price in span in some projects not showing the correct value\n",
    "        price = square_feet * price_per_square_feet\n",
    "        furnishing = get_element_text(project_div, \"span\", attrs={\"class\":\"furnishing__value\"})\n",
    "        project_list.append({\n",
    "            'title': project_info['title'],\n",
    "            'type': project_info['type'],\n",
    "            'tenure': project_info['tenure'],\n",
    "            'price': f'{price:.2f}',\n",
    "            'square_feet': square_feet,\n",
    "            'price_per_square_feet': price_per_square_feet,\n",
    "            'bedroom': bedroom,\n",
    "            'bathroom': bathroom,\n",
    "            'furnishing': furnishing,\n",
    "            'launched_in': get_year(project_info['launched_in']),\n",
    "            'address': project_info['address'],\n",
    "            'developer': project_info['developer'],\n",
    "            'description': project_info['description'],\n",
    "            'project_link': project_info['project_link'],\n",
    "            'image_link': project_info['image_link'],\n",
    "        })\n",
    "    return project_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28809392-f357-491f-9e37-a5026773bb65",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load more: 87\n",
      "Load more: 79\n",
      "Load more: 71\n",
      "Load more: 63\n",
      "Load more: 55\n",
      "Load more: 47\n",
      "Load more: 39\n",
      "Load more: 31\n",
      "Load more: 23\n",
      "Load more: 15\n",
      "Load more: 7\n",
      "Total projects: 54\n",
      "Getting project detail for: Pinnacle SJ\n",
      "Getting project detail for: Ponderosa Vista 2-Storey Semi-Detached\n",
      "Getting project detail for: Ferrous 2\n",
      "Getting project detail for: BON KIARA\n",
      "Getting project detail for: Blooming Residence\n",
      "Getting project detail for: Candella\n",
      "Getting project detail for: SouthPlace 2 Residences\n",
      "Getting project detail for: Miranda Hill\n",
      "Getting project detail for: Sejati Lakeside 2\n",
      "Getting project detail for: Tiara Sendayan\n",
      "Getting project detail for: Aderyn\n",
      "Getting project detail for: The Senai Garden\n",
      "Getting project detail for: Residensi Dian II\n",
      "Getting project detail for: Hana Residences\n",
      "Getting project detail for: Interpoint\n",
      "Getting project detail for: Sunway Flora Residences\n",
      "Getting project detail for: Pearl Garden - Panorama Lapangan Mutiara\n",
      "Getting project detail for: Senadi Hills\n",
      "Getting project detail for: Alora Residences @ 2fifth Avenue Subang Jaya\n",
      "Getting project detail for: ALTON SKYVILLAS\n",
      "Getting project detail for: Chorus\n",
      "Getting project detail for: Hanami Residences\n",
      "Getting project detail for: Ruby Hills @ BBKP\n",
      "Getting project detail for: Eco Horizon @ Beldon Collection\n",
      "Getting project detail for: Phase 6M @ Rini Homes 8\n",
      "Getting project detail for: Prestige Residence\n",
      "Getting project detail for: Greenwoods Seraya\n",
      "Getting project detail for: Myra Cove\n",
      "Getting project detail for: SkyLake Residence\n",
      "Getting project detail for: Emerald Garden 3\n",
      "Getting project detail for: Sebayu Bungalow Plots\n",
      "Getting project detail for: Ritma Perdana (Townhouse), LBS Alam Perdana\n",
      "Getting project detail for: Pangsapuri Kita Sejati\n",
      "Getting project detail for: KITA Mesra (Townhouse)\n",
      "Getting project detail for: Ponderosa Vista 2-Storey Terrace\n",
      "Getting project detail for: Sky Trees Commercial\n",
      "Getting project detail for: Edelweiss Sofo & Serviced Residences\n",
      "Getting project detail for: Ferringhi Residence 2\n",
      "Getting project detail for: Danga Sutera\n",
      "Getting project detail for: Southern Marina Residences\n",
      "Getting project detail for: Southern Marina Residences\n",
      "Getting project detail for: Jauhar @ Bayu Damai\n",
      "Getting project detail for: Rivercity Business Park @ Batu Pahat\n",
      "Getting project detail for: Suasana Iskandar Johor Bahru\n",
      "Getting project detail for: Setia Ecohill Walk\n",
      "Getting project detail for: Indah Heights\n",
      "Getting project detail for: D'Suites, Horizon Hills\n",
      "Getting project detail for: ViiA Residences at KL Eco City\n",
      "Getting project detail for: The Effingham\n",
      "Getting project detail for: Setia V Residences\n",
      "Getting project detail for: Setia Sky 88\n",
      "Getting project detail for: Molek Pine 4\n",
      "Getting project detail for: 9 Bukit Utama\n",
      "Getting project detail for: 9 Bukit Utama\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: '../data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# create data folder if not exists\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath/to/demo_folder\u001b[39m\u001b[38;5;124m\"\u001b[39m): \n\u001b[1;32m---> 18\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m today_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m     21\u001b[0m data_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mD:\\program\\anaconda\\envs\\fws-dell\\lib\\os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: '../data'"
     ]
    }
   ],
   "source": [
    "# scrape ready to buy projects from property guru web site\n",
    "url='https://www.propertyguru.com.my/new-property-launch'\n",
    "driver = uc.Chrome()\n",
    "driver.get(url)\n",
    "driver.maximize_window() \n",
    "\n",
    "# wait for cookies policy window\n",
    "time.sleep(3)\n",
    "accept_cookies_policy(driver)\n",
    "time.sleep(1)\n",
    "load_all_projects(driver)\n",
    "project_list = []\n",
    "get_projects(driver, project_list)\n",
    "\n",
    "data_folder = '../data'\n",
    "# create data folder if not exists\n",
    "if not os.path.exists(data_folder): \n",
    "    os.makedirs(data_folder)\n",
    "\n",
    "today_date = datetime.now()\n",
    "data_folder = '../data'\n",
    "filename = f'property_guru_ready_to_buy_projects_{today_date.strftime(\"%Y-%m-%d\")}.csv'\n",
    "df = pd.DataFrame(project_list)\n",
    "df.to_csv(f'{data_folder}/{filename}', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a4e363e-1129-4560-8bc7-e2b9cb05f268",
   "metadata": {},
   "outputs": [],
   "source": [
    "today_date = datetime.now()\n",
    "data_folder = '../data'\n",
    "filename = f'property_guru_ready_to_buy_projects_{today_date.strftime(\"%Y-%m-%d\")}.csv'\n",
    "df = pd.DataFrame(project_list)\n",
    "df.to_csv(f'{data_folder}/{filename}', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d424dff4-fd43-4a8b-a883-eda988d66c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.propertyguru.com.my/property-listing/project/pinnacle-sj-for-sale-by-pinnacle-homes-sdn-bhd-39482719\n"
     ]
    }
   ],
   "source": [
    "print(project_list[0]['project_link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08d833a6-3ba2-4aea-bae7-f8a8b13648a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver.get(project_list[11]['project_link'])\n",
    "#driver.get('https://www.propertyguru.com.my/property-listing/project/the-senai-garden-for-sale-by-kcc-development-m-sdn-bhd-33698731')\n",
    "driver.get('https://www.propertyguru.com.my/property-listing/project/sky-trees-commercial-for-sale-by-bukit-indah-johor-sdn-bhd-38861360')\n",
    "driver.maximize_window() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09fb8c1f-2d96-40e0-a97e-77299bf71cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c078fe84-529e-491c-b4a5-1a35873bb26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a128312f-574b-4933-8943-f2525d725e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.propertyguru.com.my/property-listing/project/southplace-2-residences-for-sale-by-tropicana-metropark-sdn-bhd-35069647'\n",
    "driver = uc.Chrome()\n",
    "driver.get(url)\n",
    "driver.maximize_window() \n",
    "\n",
    "# wait for cookies policy window\n",
    "time.sleep(3)\n",
    "accept_cookies_policy(driver)\n",
    "time.sleep(1)\n",
    "\n",
    "project_basic_info = {\n",
    "        'title': 'title',\n",
    "        'type': 'type',\n",
    "        'tenure': 'tenure',\n",
    "        'launched_in': 'launched_in',\n",
    "        'address': 'address',        \n",
    "        'project_link': 'project_link',\n",
    "        'image_link': 'image_link',\n",
    "        'developer': '',\n",
    "        'description': ''\n",
    "    }   \n",
    "\n",
    "project_list = []\n",
    "\n",
    "show_more_xpath = \"//button[normalize-space()='Show more']\"\n",
    "show_more_button = get_by_xpath(driver, show_more_xpath)\n",
    "# check if show more button exists. If exists,\n",
    "# click on it to load the complete project description\n",
    "if show_more_button:\n",
    "    driver.execute_script('arguments[0].scrollIntoView(false)', show_more_button)\n",
    "    time.sleep(1)\n",
    "    # show more button blocked by sticky div\n",
    "    # hover over to the element and click\n",
    "    hover_and_click_by_xpath(driver, show_more_xpath)\n",
    "\n",
    "# load page source to BeatifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "# get project detail section\n",
    "project_div = soup.find(\"div\", attrs={\"class\":\"col-lg-8 col-md-12\"})\n",
    "\n",
    "description = get_element_text(project_div, \"div\", attrs={\"class\":\"description\"})\n",
    "\n",
    "developer_div = project_div.find(\"div\", string='Developer')\n",
    "developer = developer_div.next_sibling.text.strip()\n",
    "\n",
    "bedrooms_types_nav = project_div.find(\"nav\", attrs={'data-automation-id':'unit-types-navbar'})\n",
    "if bedrooms_types_nav:\n",
    "    bedrooms_types = bedrooms_types_nav.find_all(\"a\")\n",
    "    for bedrooms_type in bedrooms_types:\n",
    "        bedrooms_type_xpath = f\"//a[normalize-space()='{bedrooms_type.text.strip()}']\"\n",
    "        bedrooms_type_tab = get_by_xpath(driver, bedrooms_type_xpath)\n",
    "        driver.execute_script('arguments[0].scrollIntoView(false)', bedrooms_type_tab)\n",
    "        time.sleep(1)\n",
    "        hover_and_click_by_xpath(driver, bedrooms_type_xpath)\n",
    "        time.sleep(2)\n",
    "        # reload page source\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        project_div = soup.find(\"div\", attrs={\"class\":\"col-lg-8 col-md-12\"})\n",
    "        price = get_element_text(project_div, \"span\", attrs={\"class\":\"price__label\"})\n",
    "        if price is None:\n",
    "            # skip is price span does not exists\n",
    "            continue\n",
    "        project_list.extend(get_unit_type_info(driver, project_basic_info, project_div))\n",
    "else:\n",
    "    project_list.extend(get_unit_type_info(driver, project_basic_info, project_div))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8ec1170-a4b5-452e-9a5d-735492464dcf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   {   'address': 'address',\n",
      "        'bathroom': '1',\n",
      "        'bedroom': '1',\n",
      "        'description': '',\n",
      "        'developer': '',\n",
      "        'furnishing': 'Partially Furnished',\n",
      "        'image_link': 'image_link',\n",
      "        'launched_in': 'N/A',\n",
      "        'price': '505997.36',\n",
      "        'price_per_square_feet': 867.92,\n",
      "        'project_link': 'project_link',\n",
      "        'square_feet': 583,\n",
      "        'tenure': 'tenure',\n",
      "        'title': 'title',\n",
      "        'type': 'type'},\n",
      "    {   'address': 'address',\n",
      "        'bathroom': '2',\n",
      "        'bedroom': '2',\n",
      "        'description': '',\n",
      "        'developer': '',\n",
      "        'furnishing': 'Partially Furnished',\n",
      "        'image_link': 'image_link',\n",
      "        'launched_in': 'N/A',\n",
      "        'price': '588003.34',\n",
      "        'price_per_square_feet': 775.73,\n",
      "        'project_link': 'project_link',\n",
      "        'square_feet': 758,\n",
      "        'tenure': 'tenure',\n",
      "        'title': 'title',\n",
      "        'type': 'type'},\n",
      "    {   'address': 'address',\n",
      "        'bathroom': '2',\n",
      "        'bedroom': '3',\n",
      "        'description': '',\n",
      "        'developer': '',\n",
      "        'furnishing': 'Partially Furnished',\n",
      "        'image_link': 'image_link',\n",
      "        'launched_in': 'N/A',\n",
      "        'price': '788003.51',\n",
      "        'price_per_square_feet': 809.87,\n",
      "        'project_link': 'project_link',\n",
      "        'square_feet': 973,\n",
      "        'tenure': 'tenure',\n",
      "        'title': 'title',\n",
      "        'type': 'type'},\n",
      "    {   'address': 'address',\n",
      "        'bathroom': '2',\n",
      "        'bedroom': '4',\n",
      "        'description': '',\n",
      "        'developer': '',\n",
      "        'furnishing': 'Partially Furnished',\n",
      "        'image_link': 'image_link',\n",
      "        'launched_in': 'N/A',\n",
      "        'price': '867005.10',\n",
      "        'price_per_square_feet': 784.62,\n",
      "        'project_link': 'project_link',\n",
      "        'square_feet': 1105,\n",
      "        'tenure': 'tenure',\n",
      "        'title': 'title',\n",
      "        'type': 'type'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(project_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98cac53-f4e6-46c9-a9e1-1dcb44394c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
